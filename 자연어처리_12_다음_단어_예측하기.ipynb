{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8QvxmWfAHJdVoVThAfWsL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leejunho12316/NLP-study/blob/main/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_12_%EB%8B%A4%EC%9D%8C_%EB%8B%A8%EC%96%B4_%EC%98%88%EC%B8%A1%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 전처리"
      ],
      "metadata": {
        "id": "W2ZHGgLbcEC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XJ4FlHazG19i"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터\n",
        "data = \"\"\"Moon and the stars with a great grand muntain\\n\n",
        "          Stood a great dick which was mine\\n\n",
        "          She was in madness wanting this sticky white icecream\\n\n",
        "          Flooding out like a milk\\n\n",
        "          Their flesh and bones were beating each other\"\"\""
      ],
      "metadata": {
        "id": "kpdEHnUsFqRk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#정수 인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "encoded = tokenizer.texts_to_sequences([data])[0]\n",
        "print(encoded)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVEfrNKxG0OI",
        "outputId": "da261b7f-0b02-40ca-f87a-72e6f7f24292"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 2, 6, 7, 8, 1, 3, 9, 10, 11, 1, 3, 12, 13, 4, 14, 15, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 1, 26, 27, 28, 2, 29, 30, 31, 32, 33]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#두개씩 페어링된 데이터셋 만들기\n",
        "seq = []\n",
        "for i in range(0,len(encoded)-1): #range(0,37) 15까지 index15 encoded[15:17]\n",
        "  seq.append(encoded[i:i+2])\n",
        "\n",
        "seq = np.array(seq)\n",
        "x = seq[:, 0]\n",
        "y = seq[:, 1]\n",
        "print(\"x=\",x)\n",
        "print(\"y=\",y.dtype)"
      ],
      "metadata": {
        "id": "u76ougzqG_Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ddeef8-b617-403a-e807-5a948dcdc1c6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x= [ 5  2  6  7  8  1  3  9 10 11  1  3 12 13  4 14 15  4 16 17 18 19 20 21\n",
            " 22 23 24 25  1 26 27 28  2 29 30 31 32]\n",
            "y= int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 신경망"
      ],
      "metadata": {
        "id": "Hr4ptbNMZ2T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "XATci3uWcG6K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(input_dim = vocab_size, output_dim = 10, input_length = 1))\n",
        "model.add(layers.LSTM(50))\n",
        "model.add(layers.Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(x,y, epochs=500, verbose=2)"
      ],
      "metadata": {
        "id": "sbPloCtVcWGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 테스트 해보기"
      ],
      "metadata": {
        "id": "uS21WmUJlKGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"was\"\n",
        "test = tokenizer.texts_to_sequences([test])[0]\n",
        "test = np.array(test)\n",
        "\n",
        "output = model.predict(test)\n",
        "result = np.argmax(output)\n",
        "\n",
        "for key, index in tokenizer.word_index.items():\n",
        "  if index == result:\n",
        "    print(key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoeNSwTpdu6Q",
        "outputId": "534e999a-4969-48ad-a7ea-623515e528ba"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0lQeWXekV7S",
        "outputId": "9d462b89-887f-46ac-ca1d-12161d63f34f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "값 :  with\n"
          ]
        }
      ]
    }
  ]
}